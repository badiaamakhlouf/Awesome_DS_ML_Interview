{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20126c01",
   "metadata": {},
   "source": [
    "# Data Scientist Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143e643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f01c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1637841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f66d794",
   "metadata": {},
   "source": [
    "## Wha means normal distribution\n",
    "The normal distribution is very useful in machine learning becasue it has deterministic statistical characteristics  and it helps detect linear relationship between variables. It consists that mode=mean=median: \n",
    "\n",
    "- Mean: called also average of a data set and it is found by summing all numbers in the data set and then dividing by the number of values in the set.\n",
    "- Mode : it is the value that appears most often in a set of data values.\n",
    "- Median : the middle number; found by ordering all data points and picking out the one in the middle (or if there are two middle numbers, taking the mean of those two numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87050441",
   "metadata": {},
   "source": [
    "### Polynomial transformation \n",
    "if X is one input feature ==> X^2 is its polynomial feature. This process can be repeated for each input variable in the dataset, creating a transformed version of each.The “degree” of the polynomial is used to control the number of features added, e.g. a degree of 3 will add two new variables for each input variable. Typically a small degree is used such as 2 or 3. Choosing the best polynomial degree is so important as it impacts the number of input features created. \n",
    "\n",
    "Squaring or cubing an input variable changes its probability distribution, creating a distinction between small and large values. This distinction is amplified with a higher exponent. Such transformations are often beneficial for machine learning algorithms, particularly in tasks involving numerical input variables, improving predictive accuracy, especially in regression tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcb376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220d308f",
   "metadata": {},
   "source": [
    "The effectiveness of numerous machine learning algorithms diminishes when dealing with variables featuring non-standard probability distributions. This holds true for both real-valued input variables in classification and regression tasks, as well as real-valued target variables in regression tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d28d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

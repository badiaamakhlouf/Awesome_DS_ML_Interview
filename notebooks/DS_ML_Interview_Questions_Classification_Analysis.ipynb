{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835fc9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72734e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc5500b",
   "metadata": {},
   "source": [
    "### 4- Examples of well-known machine learning algorithms used to solve classification problems\n",
    "\n",
    "Certainly! Here are some well-known machine learning algorithms commonly used to solve classification problems:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector Machines (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Naive Bayes\n",
    "- Neural Networks (Deep Learning)\n",
    "- AdaBoost\n",
    "- Gradient Boosting Machines (GBM)\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c20834",
   "metadata": {},
   "source": [
    "### 14- How to evaluate a Classification model?\n",
    "\n",
    "- Many metrics are commonly used to evaluate the performance of classification models in machine learning.\n",
    "- The choice of metrics depends on the specific goals and characteristics of the classification problem.\n",
    "- Here are some classification metrics:\n",
    "    - Confusion matrix\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - F1 Score\n",
    "    - Recall (Sensitivity or True Positive Rate)\n",
    "    - Specificity or True Negative Rate\n",
    "    - Area Under the Receiver Operating Characteristic (ROC) Curve (AUC-ROC)\n",
    "    - Area Under the Precision-Recall Curve (AUC-PR) \n",
    "- The choice of metrics depends on the specific requirements of the classification problem (binary classification or multiclass classification).\n",
    "- For example, in imbalanced datasets, where one class significantly has large number of samples than the second class, precision, recall, and F1 score are often more informative than accuracy.\n",
    "\n",
    "#### 14. 1- What is confusion matrix in classification problems?\n",
    "\n",
    "- Confusion matrix is a table used to measure the performance of classification model\n",
    "- It gives more details regarding the number of instances that were correctly or incorrectly classified for each class.\n",
    "- The confusion matrix is a valuable tool for assessing the strengths and weaknesses of a classification model and guiding further optimization efforts.\n",
    "- Here is an example of confusion matrix for a binary classification problem : \n",
    "![title](images/confusion-matrix1.jpeg)\n",
    "##### a. True Positive : \n",
    "- samples that are from the positive class and were correctly classified or predicted as positive by the model.\n",
    "##### b. True Negative :  \n",
    "- samples that are from the negative class and were correctly classified or predicted as negative by the model.\n",
    "##### c. False Positive : \n",
    "- samples that are from  the negative class but were incorrectly classified or predicted as positive by the model.\n",
    "##### d. False Negative : \n",
    "- samples that are from  the positive class but were incorrectly classified or predicted as negative by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe5eda",
   "metadata": {},
   "source": [
    "#### 14. 2- How to define Accuracy?\n",
    "\n",
    "- An evaluation metric used to evaluate the performance of classification model.\n",
    "\n",
    "- Divides the number of correctly classified observations by the total number of samples.\n",
    "\n",
    "- **Formula:** $$Accuracy ={ Number  of Correct Predictions \\over Total number of predictions }$$\n",
    "\n",
    "\n",
    "- Here a second formula : $$Accuracy ={ TP + TN \\over TP + TN + FP + FN }$$\n",
    "\n",
    "#### 14. 3- How to define Precision ?\n",
    "- An evaluation metric that measures the accuracy of the positive predictions made by the model. \n",
    "- It divides the number of true positive predictions by the sum of true positives and false positives.\n",
    "- It belongs to [0,1] interval, 0 corresponds to no precision and 1 corresponds to perfect precision.\n",
    "- Precision = Positive Predictive Power\n",
    "- **Formula:** $$Precision = {True Positives \\over True Positives + False Positives}$$ \n",
    "\n",
    "#### 14. 4- How to define Recall, Sensitivity or True Positive Rate?\n",
    "- An evaluation metric that measures the ability of the model to capture all the positive samples.\n",
    "- It divides number of true positives samples by the sum of true positives and false negatives.\n",
    "- Recall = Sensitivity = True Positive Rate. \n",
    "- **Formula:** $$ Recall= {True Positives \\over True Positives + False Negatives}$$\n",
    "#### 14. 5- How to define F1-score? \n",
    "- An evaluation metric that combines both Precision and Recall.\n",
    "- Wighted average of Precision and Recall.\n",
    "- It can be calculated using the `f1_score()` function of `scikit-learn`\n",
    "- F1 belongs to [0,1]: 0 is the worst case and 1 is the best.\n",
    "- **Formula :** $$F1= {2×Precision×Recall \\over Precision+Recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7ed74",
   "metadata": {},
   "source": [
    "#### 14. 5- How to define Specificity or True Negative Rate ?\n",
    "- Specificity measures the ability of the model to correctly identify negative instances.\n",
    "- It divides the true negatives samples by the sum of true negatives observations and false positives observations.\n",
    "- True Negative Rate = Specificity\n",
    "- **Formula:** $$Specificity={True Negatives \\over True Negatives + False Positives}$$ \n",
    "#### 14. 6- What is Receiver Operating Characteristic (ROC) and Area under-ROC curve (AUC-ROC)?\n",
    "- ROC curve is a graphical representation of the model's performance across different classification thresholds.\n",
    "- The shape of the curve contains a lot of information\n",
    "- Area under the ROC curve : AUC-ROC provides a single metric indicating the model's ability to distinguish between classes.\n",
    "- Here is ROC and AUC-ROC illustration:\n",
    "\n",
    "![title](images/roc-curve-original.png)\n",
    "\n",
    "- If AUC-ROC is high, then we have better model. Else, we have poor model performance.\n",
    "- Smaller values on the x-axis of the curve point out lower false positives and higher true negatives.\n",
    "- Larger values on the y-axis of the plot indicate higher true positives and lower false negatives.\n",
    "- We can plot the ROC curve using the `roc_curve()` scikit-learn function.\n",
    "- To calculate the accuracy, we use `roc_auc_score()` function of `scikit-learn`.\n",
    "* Note: False Positive Rate = 1- Specificity\n",
    "\n",
    "\n",
    "\n",
    "*source: https://sefiks.com/2020/12/10/a-gentle-introduction-to-roc-curve-and-auc/\n",
    "\n",
    "#### 14. 7- What is Area Under the Precision-Recall Curve (AUC-PR)?\n",
    "- Similar to AUC-ROC, AUC-PR represents the area under the precision-recall curve.\n",
    "- It provides a summary measure of a model's performance across various levels of precision and recall.\n",
    "- It can be calculated using the `precision_recall_curve()` function of `scikit-learn`.\n",
    "- The area under the precision-recall curve can be calculated using the `auc()` function of `scikit-learn` taking the recall and precision as input.\n",
    "\n",
    "![title](images/precision_recall_curve.png)\n",
    "\n",
    "*source: https://analyticsindiamag.com/complete-guide-to-understanding-precision-and-recall-curves/\n",
    "\n",
    "- The same here if AUC-PR is high, then we have better model. Else, we have poor model performance.\n",
    "- The recall is provided as the x-axis and precision is provided as the y-axis.\n",
    "#### a. When to Use ROC vs. Precision-Recall Curves?\n",
    "- Choosing either the ROC curves or precision-recall curves depends on your data distribution:\n",
    "    - ROC curves: preferable to be used when there are roughly equal numbers of observations for each class.\n",
    "    - ROC curves provide a good picture of the model when the dataset has large class imbalance.\n",
    "    - Precision-Recall curves should be used when there is a moderate to large class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912767e",
   "metadata": {},
   "source": [
    "#### 14. 8 - Classification Report Scikit-learn? \n",
    "- The `classification_report` function of `scikit-learn` provides a detailed summary of classification metrics for each class in a classification problem. \n",
    "- The report contains the next metrics:\n",
    "    - Precision\n",
    "    - Recall- sensitivity\n",
    "    - F1-score\n",
    "    - Specificity\n",
    "    - Support\n",
    "- Support: the number of actual instances of each class in the dataset.\n",
    "#### 14. 9- How do we evaluate a classification report?\n",
    "- High recall + high precision ==> the class is perfectly handled by the model. \n",
    "- Low recall + high precision ==> the model can not detect the class well but is highly trustable when it does.\n",
    "- High recall + low precision ==> the class is well detected but model also includes points of other class in it. \n",
    "- Low recall + low precision ==> class is poorly handled by the model\n",
    "#### 14. 10 What is log loss fucntion?\n",
    "- It is an evaluation metric used in logistic regression\n",
    "- Called logistic regression loss or cross-entropy loss\n",
    "- Input of this loss function is probability value that belongs to [0,1].\n",
    "- It measures the uncertaintly of our prediction based on how much it varies from the actual label.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc50184",
   "metadata": {},
   "source": [
    "### 16. how to choose a classifier based on training dataset size?\n",
    "- If training set is small ==> it is better to use simple model with high bias and low variance seems to work better because they are less likely to overfit. \n",
    "- If training set is large ==> it is better to use model with low bias and high variance as this model type will tend to perform better with complex relationships. Example: Naive Bayes.\n",
    "-  Balancing variance and bias is essential for developing models that perform well on both training and unseen data.\n",
    "\n",
    "#### 16. 1-  What is data bias ?\n",
    "- It is when the available data used in the training phase is not representative of the real-world population or phenomen of study.\n",
    "- For example: when training data used to create a ml model has unfair discrepancies or inaccuracies. \n",
    "- The information provided by the data does not truly represent the situation.\n",
    "- The existence of biased data can lead to undesired and often unfair outcomes (discriminatory results) when the model is applied to testing data because the model will learn these biases too. \n",
    "- Various types of bias are existing : selection bias, measurement bias and confirmation bias.\n",
    "- Addressing data bias is an ongoing challenge in the field of machine learning, and researchers and practitioners are actively working to develop methods and tools to identify, measure, and mitigate bias in models.\n",
    "- To mitigate data bias in machine learning, it's crucial to accomplish well studied steps: collecting diverse and representative data, thoroughly processing it, and regularly checking model predictions to ensure fairness.\n",
    "- Example: a biased facial recognition model may perform poorly for certain demographic groups.\n",
    "\n",
    "#### 16. 2-  What is variance? \n",
    "\n",
    "- Understanding variance is crucial in assessing the stability and generalization capability of models.\n",
    "- It refers to the degree of spread or dispersion in a set of values.\n",
    "- It measures the variability of each individual data points (observation) from the mean (average) of the dataset:\n",
    "    - Higher variance: data points are more spread out from the mean ==> more dispersed distribution.\n",
    "    - Lower variance:  data points are closer to the mean ==> more concentrated distribution.\n",
    "- Formula:  $\\sigma^2 = { \\sum \\limits _{i=1} ^{n}(X_{i} - \\overline{X}) \\over {n-1}}$\n",
    "- The standard deviation ( $\\sigma$) is the square root of the variance.\n",
    "- If the predictions variance is :\n",
    "    - Low: predictions varying little from each other. \n",
    "    - High: overfitting + reading too deelpy into the noise+ good performance on training data +poor performance on testing data\n",
    "- Do not forget the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b72f88",
   "metadata": {},
   "source": [
    "### How Logistic regression works ?\n",
    "- It is a classification algorithm used to predict a discret output.\n",
    "- Types of outputs: \n",
    "    - Binary (2 classes)\n",
    "    - Multiple (>2 classes)\n",
    "    - Ordianl (Low, medium, High)\n",
    "- It uses the sigmoid activation function to map predictions to probabilities\n",
    "- Output:mx+b\n",
    "- Sigmoid function formula: $$S(z)={1\\over 1+ e^{-z}}$$\n",
    "<div>\n",
    "<img src=\"images/sigmoid-function.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f218af",
   "metadata": {},
   "source": [
    "### What is 'naive' in the Naive Bayes classifier?\n",
    "- The classifier is called 'naive' because it makes assumptions that may or may not turn out to be correct\n",
    "- The algorithm assumes the absolute independence of features==>the presence of one feature of a class is not related to the presence of any other feature\n",
    "- Example: any fruit that is red and round is cherry ==> it can be true or false\n",
    "### How to knwo which ML algorithm to use for your classification problem ?\n",
    "- There is no fixed rule to choose. However, you can follow these guidelines: \n",
    "    - If accuracy is a concern ==> test different algorithms and cross-validate them\n",
    "    - If the training dataset is small ==> use models that have low varaiance and high bias\n",
    "    - If the training dataset is large ==> use models that have high variance and littke bias\n",
    "### How to choose which ML algorithm tu use given a dataset?\n",
    "- No master algorithm it all depends on the situation\n",
    "- Answer the next questions: \n",
    "    - How much data?\n",
    "    - Output: Continous, Categorical?\n",
    "    - Is it classification, regression or clustering?\n",
    "    - Is all output variables labled or mixed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79b120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578b3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

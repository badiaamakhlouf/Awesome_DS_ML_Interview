{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20126c01",
   "metadata": {},
   "source": [
    "# Data Scientist Interview Questions\n",
    "## Part 3 : ML : modelling and evaluation\n",
    "\n",
    "This Jupyter notebook serves as a focused resource for individuals gearing up for technical interviews in the fields of machine learning engineering and data science. It specifically delves into questions related to all phases of machine learning model evaluation and deployment. Whether you're a candidate looking to sharpen your interview skills or an interviewer seeking insightful questions, this notebook provides valuable content for honing your understanding of machine learning evaluation and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27572c9",
   "metadata": {},
   "source": [
    "### 0- What does Machine Learning means ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb4290",
   "metadata": {},
   "source": [
    "### 1- What are three stages of building a machine learning model ? \n",
    "- The process of building a machine learning model includes three main stages, These stages are:\n",
    "    - **Training phase:** after splitting the data into training and testing sets, training data is used to train our model on a labeled dataset. During the training phase, the model tries to learn relationships between input data and the corresponding output target values while adjusting its internal parameters. Throughout this phase, the model aims to maximise the accuracy of making precise predictions or classifications when exposed to unseen data.\n",
    "    - **Validation phase:** after the model is well trained, we evaluate it on a seperate dataset known as the validation set (maximum 10% of our data). This dataset is not used during the training process. Validation stage helps identify the existence of certain overfitting (model performing well on training data but poorly on new data) or certain underfitting (model needs more training to capture the underlying patterns in the data).\n",
    "    - **Testing (Inference) phase:** during this phase, the trained and validated model is applied to unseen dataset, called test dataset. This phase aims to evaluate the model's performance and provides a measure regarding the model's effectiveness and its ability to make accurate predictions in a production environment.\n",
    "    \n",
    "#### 1. 1- How to split your data while building a machine learning model ?    \n",
    "- During the model building phase, it is required to split the data into three main sets to evaluate the model's performance and effectiveness. The three sets are: \n",
    "    - Training: used to train the model and learn relationship between inputs and outputs, contains 70-80% of our total dataset\n",
    "    - Validation: used to validate the model, fine-tune the model's hyperparameters and assess its performance during training, it helps to prevent overfitting and underfitting. It contains 10-15% of the total data\n",
    "    - Testing: used to test and evaluate the model's performance against unseen data and after validation phase. It is used to measure how effective will our built model be in a production environment. It contains 10-15% of the total data.\n",
    "\n",
    "- Splitting data is accomplished after the preprocessing phase (handle missing values, categorical features, scale features, etc.). \n",
    "- It is important to ensure that the split is representative of the overall distribution of the data to avoid biased results.\n",
    "- It is favorable to use cross-validation technique. \n",
    "- No fixed rule to split data between training, validation and testing, portions can vary based on individual preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db499b",
   "metadata": {},
   "source": [
    "### 2- What are the types of ML algorithms ? \n",
    "Machine learning algorithms can be categorized into several types based on their learning styles and the nature of the task they are designed to solve.\n",
    "\n",
    "Here are some common types of machine learning algorithms:\n",
    "- **Supervised Learning** \n",
    "- **Unsupervised Learning**\n",
    "- **Semi-Supervised Learning**\n",
    "- **Deep Learning** \n",
    "- **Reinforcement Learning** \n",
    "- **Ensemble learning**  \n",
    "- **Ranking**\n",
    "- **Recommendation system** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47970ec3",
   "metadata": {},
   "source": [
    "#### 2.1 - What does supervised, unsupervised and semi-supervised means in ML? \n",
    "\n",
    "In machine learning, the terms \"supervised learning,\" \"unsupervised learning,\" and \"semi-supervised learning\" refer to different approaches based on the type of training data available and the learning task at hand:\n",
    "\n",
    "- **Supervised Learning :** training a model on a labeled dataset, where the algorithm learns the relationship between input features and corresponding target labels. Can be used for Regression (continous output) or Classification (discrete output). \n",
    "- **Unsupervised Learning :** Deals with unlabeled data and aims to find patterns, structures, or relationships within the data. Can be used for Clustering (Groups similar data points together) or association\n",
    "- **Semi-Supervised Learning:** Utilizes a combination of labeled and unlabeled data to improve learning performance, often in situations where obtaining labeled data is challenging and expensive.\n",
    "\n",
    "#### 2.2 - What are Unsupervised Learning techniques ?\n",
    " We have two techniques, Clustering and association: \n",
    " - Custering :  involves grouping similar data points together based on inherent patterns or similarities. Example: grouping customers with similar purchasing behavior for targeted marketing.. \n",
    " - Association : identifying patterns of associations between different variables or items. Example: e-commerse website suggest other items for you to buy based on prior purchases.\n",
    "#### 2.3 - What are Supervised Learning techniques ? \n",
    "We have two techniques: classfication and regression: \n",
    "- Regression : involves predicting a continuous output or numerical value based on input features. Examples : predicting house prices, temperature, stock prices etc.\n",
    "- Classification : is the task of assigning predefined labels or categories to input data. We have two types of classification algorithms: \n",
    "    - Binary classification (two classes). Example: identifying whether an email is spam or not.\n",
    "    - Multiclass classification (multiple classes). Example: classifying images of animals into different species."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb48e0",
   "metadata": {},
   "source": [
    "### 3- Examples of well-known machine learning algorithms used to solve regression problems\n",
    "\n",
    "Certainly! Here are some well-known machine learning algorithms commonly used to solve regression problems:\n",
    "\n",
    "- Linear Regression\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Gradient Boosting Algorithms (e.g., XGBoost, LightGBM)\n",
    "- Support Vector Machines (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Bayesian Regression\n",
    "- Neural Networks (Deep Learning):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b2972",
   "metadata": {},
   "source": [
    "### 4- Examples of well-known machine learning algorithms used to solve classification problems\n",
    "\n",
    "Certainly! Here are some well-known machine learning algorithms commonly used to solve classification problems:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Support Vector Machines (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Naive Bayes\n",
    "- Neural Networks (Deep Learning)\n",
    "- AdaBoost\n",
    "- Gradient Boosting Machines (GBM)\n",
    "- XGBoost\n",
    "- CatBoost\n",
    "- LightGBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fc2a5",
   "metadata": {},
   "source": [
    "### 5- Examples of well-known machine learning algorithms used to solve clustering problems\n",
    "\n",
    "Several well-known machine learning algorithms are commonly used for solving clustering problems. Here are some examples:\n",
    "\n",
    "- K-Means Clustering \n",
    "- Hierarchical Clustering\n",
    "- DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "- Mean Shift\n",
    "- Gaussian Mixture Model (GMM)\n",
    "- Agglomerative Clustering\n",
    "\n",
    "These algorithms address different types of clustering scenarios and have varying strengths depending on the nature of the data and the desired outcomes. The choice of clustering algorithm often depends on factors such as the shape of clusters, noise in the data, and the number of clusters expected.\n",
    "\n",
    "#### 5.1- K-Means \n",
    "\n",
    "#### 5.2- Hierarchical Clustering Versus Agglomerative Clustering\n",
    "Hierarchical clustering is a type of clustering algorithm, and agglomerative clustering is a specific approach within hierarchical clustering: \n",
    "- **Hierarchical Clustering :** starts with each data point as a separate cluster and then iteratively merges or splits clusters based on their similarity, forming a dendrogram. It can be broadly classified into two types: agglomerative (bottom-up) and divisive (top-down).\n",
    "- **Agglomerative Clustering :** is a specific approach within hierarchical clustering. Here is how it works : \n",
    "    - Each data point is initially a separate cluster.\n",
    "    - The closest pair of clusters is merged into a single cluster.\n",
    "    - Steps 1 and 2 are repeated until all data points belong to a single cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce66ed5",
   "metadata": {},
   "source": [
    "### 6 -What is Ensemble learning?\n",
    "\n",
    "Ensemble learning is a machine learning technique that involves combining the predictions of multiple individual models to improve overall performance and accuracy. Instead of relying on a single model, ensemble methods leverage the strengths of diverse models to compensate for each other's weaknesses. The idea is that by aggregating the predictions of multiple models, the ensemble can achieve better generalization and make more robust predictions than any individual model.\n",
    "\n",
    "There are several ensemble learning methods, with two primary types being:\n",
    "- **Bagging (Bootstrap Aggregating) :** \n",
    "    - Involves training multiple instances of the same model on different subsets of the training data, typically sampled with replacement. \n",
    "    - Examples : Random Forest, Bagged Decision Trees, Bagged SVM (Support Vector Machines), Bagged K-Nearest Neighbors, Bagged Neural Networks\n",
    "- **Boosting :**\n",
    "    - Focuses on sequentially training models, with each subsequent model giving more attention to the instances that the previous models misclassified. \n",
    "    - Examples: AdaBoost (Adaptive Boosting), Gradient Boosting, XGBoost (Extreme Gradient Boosting), LightGBM (Light Gradient Boosting Machine), CatBoost, GBM (Gradient Boosting Machine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c0243",
   "metadata": {},
   "source": [
    "### 7 -What is Deep Learning?\n",
    "\n",
    "Is a subset of machine learning that involves training artificial neural networks with multiple layers (deep neural networks) to model complex patterns and representations. The term \"deep\" refers to the depth of the neural network, which consists of multiple hidden layers through which data is processed.\n",
    "\n",
    "It has achieved remarkable success in various domains, including image and speech recognition, natural language processing, and game playing. It eliminates the need for manual feature engineering by automatically learning hierarchical representations from raw data during the training process. Deep learning models are trained using large amounts of data and are capable of capturing complex patterns and representations.\n",
    "\n",
    "We have two main examples :\n",
    "- Convolutional Neural Networks (CNNs) for image processing\n",
    "- Recurrent Neural Networks (RNNs) for sequence data.\n",
    "\n",
    "#### 7. 1- What is neural network?\n",
    "#### 7. 2- What is Convolutional Neural Networks : CNNs? \n",
    "#### 7. 3- What is Recurrent Neural Networks : RNNs? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176b31a",
   "metadata": {},
   "source": [
    "### 8- What is Recommender Systems\n",
    "Also known as recommendation systems or engines, are applications or algorithms designed to suggest items or content to users based on their preferences and behavior. These systems leverage data about users and items to make personalized recommendations, aiming to enhance user experience and satisfaction. There are two main types of recommender systems:\n",
    "\n",
    "- Content-Based Recommender Systems\n",
    "- Collaborative Filtering Recommender Systems\n",
    "Recommender systems are widely used in various industries, including e-commerce, streaming services, social media, and more. They help users discover new items, increase user engagement, and contribute to business success by promoting relevant content and products\n",
    "\n",
    "#### 8. 1- What is Content-Based Recommender Systems ? \n",
    "#### 8. 2- What is Collaborative Filtering Recommender Systems ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b831fc9",
   "metadata": {},
   "source": [
    "### 9 -What is Reinforcement Learning?\n",
    "\n",
    "Is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions, allowing it to learn optimal strategies over time to maximize cumulative rewards. It is inspired by the way humans and animals learn from trial and error.\n",
    "\n",
    "Here are some applications of Reinforcement Learning : \n",
    "- Automated Robots\n",
    "- Natural Language Processing\n",
    "- Marketing and Advertising \n",
    "- Image Processing\n",
    "- Recommendation Systems\n",
    "- Traffic Control \n",
    "- Healthcare \n",
    "- Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba017a",
   "metadata": {},
   "source": [
    "### 10- What is Ranking ? \n",
    "\n",
    "Ranking in machine learning refers to the process of assigning a meaningful order or ranking to a set of items based on their relevance or importance. This is often used in scenarios where the goal is to prioritize or sort items based on their predicted or observed characteristics.\n",
    "\n",
    "Ranking problems are common in various applications, including information retrieval, recommendation systems, and search engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece0440",
   "metadata": {},
   "source": [
    "### 11- Overfitting and Underfitting\n",
    "\n",
    "Overfitting and underfitting are common challenges in machine learning that relate to the performance of a model on unseen data.\n",
    "- Overfitting : occurs when a machine learning model learns the training data too well, capturing noise and random fluctuations in addition to the underlying patterns (as concept). High error on testing dataset\n",
    "\n",
    "- Underfitting : happens when a model is too simplistic and cannot capture the underlying patterns in the training data. High error rate on both training and testing datasets.\n",
    "\n",
    "#### 11. 1 - Overfitting Causes and Mitigation:\n",
    "- Causes:\n",
    "    - Too many features or parameters.\n",
    "    - Complex model architectures.\n",
    "    - Limited training data.\n",
    "- Consequences\n",
    "- Mitigation:\n",
    "    - Regularization techniques (e.g., L1 or L2 regularization).\n",
    "    - Feature selection or dimensionality reduction.\n",
    "    - Increasing the amount of training data.\n",
    "    - Using simpler model architectures.==> Less variables and parameters so variance can be reduced.\n",
    "    - Use of Cross-validation method \n",
    "    \n",
    "#### 11. 2 - Underfitting Causes and Mitigation:\n",
    "- Causes:\n",
    "    - Too few features or parameters.\n",
    "    - Insufficient model complexity.\n",
    "    - Inadequate training time or data.\n",
    "- Mitigation:\n",
    "    - Increasing the complexity of the model.\n",
    "    - Adding relevant features.\n",
    "    - Training for a longer duration.\n",
    "    - Considering more sophisticated model architectures.\n",
    "\n",
    "Achieving a balance between overfitting and underfitting is crucial. This balance, often referred to as the model's \"sweet spot,\" results in a model that generalizes well to new, unseen data. Techniques like cross-validation, hyperparameter tuning, and monitoring learning curves can help strike this balance during the model development process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b8142",
   "metadata": {},
   "source": [
    "### 12- What are the types of Regularization in Machine Learning\n",
    "\n",
    "Regularization is a technique used in machine learning to prevent overfitting by adding a penalty term to the objective function. There are mainly two types of regularization commonly used: L1 regularization (Lasso) and L2 regularization (Ridge). Additionally, Elastic Net is a combination of both L1 and L2 regularization. \n",
    "\n",
    "Here are all the used techniques in ML : \n",
    "- L1 Regularization (Lasso)\n",
    "- L2 Regularization (Ridge)\n",
    "- Elastic Net\n",
    "\n",
    "#### 12. 1 - L1 Regularization (Lasso) : \n",
    "L1 regularization tends to shrink some coefficients exactly to zero, effectively excluding the corresponding features from the model. It is often used when there is a belief that some features are irrelevant. The penalty term is the sum of the absolute values of the regression coefficients.\n",
    "\n",
    "#### 12. 2 - L2 Regularization (Ridge) : \n",
    "\n",
    "L2 regularization tends to shrink coefficients toward zero without eliminating them entirely. It is effective in dealing with multicollinearity (high correlation between predictors) and preventing overfitting. The penalty term is the sum of the squared values of the regression coefficients.\n",
    "\n",
    "\n",
    "#### 12. 3 - Elastic Net: \n",
    "\n",
    "Elastic Net combines both L1 and L2 penalties in the objective function. It has two control parameters, alpha (which controls the overall strength of regularization) and the mixing parameter, which determines the ratio between L1 and L2 penalties. It is useful when there are many correlated features, and it provides a balance between Lasso and Ridge.\n",
    "\n",
    "\n",
    "These regularization techniques help improve the generalization performance of machine learning models by preventing them from becoming too complex and fitting noise in the training data. The choice between L1, L2, or Elastic Net depends on the specific characteristics of the dataset and the modeling goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598bc8b",
   "metadata": {},
   "source": [
    "### 13- What is Model Validation Technique?\n",
    "\n",
    "Validation techniques in machine learning are essential for assessing the performance of a model and ensuring its ability to generalize well to unseen data. \n",
    "\n",
    "Here are some common validation techniques:\n",
    "- Train-Test Split \n",
    "- K-Fold Cross-Validation \n",
    "- Stratified K-Fold Cross-Validation\n",
    "- Leave-One-Out Cross-Validation (LOOCV)\n",
    "- Holdout Validation\n",
    "- Time Series Cross-Validation\n",
    "\n",
    "#### 13. 1 - What is train-test-validation split?\n",
    "#### 13. 2 - What is K-Fold Cross-Validation?\n",
    "#### 13. 3 - What is Stratified K-Fold Cross-Validation? \n",
    "#### 13. 4 - What is Leave-One-Out Cross-Validation (LOOCV)?\n",
    "#### 13. 5 - What is Holdout Validation ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024fcc75",
   "metadata": {},
   "source": [
    "### 14- How to evaluate a Classification model?\n",
    "- Many metrics are commonly used to evaluate the performance of classification models in machine learning.\n",
    "- The choice of metrics depends on the specific goals and characteristics of the classification problem.\n",
    "- Here are some classification metrics:\n",
    "    - Confusion matrix\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - F1 Score\n",
    "    - Recall (Sensitivity or True Positive Rate)\n",
    "    - Specificity or True Negative Rate\n",
    "    - Area Under the Receiver Operating Characteristic (ROC) Curve (AUC-ROC)\n",
    "    - Area Under the Precision-Recall Curve (AUC-PR)\n",
    "- For example, in imbalanced datasets, where one class significantly has large number of samples than the second class, precision, recall, and F1 score are often more informative than accuracy. \n",
    "\n",
    "#### 14. 1- What is confusion matrix in classification problems?\n",
    "#### 14. 2- How to define Accuracy?\n",
    "#### 14. 3- How to define Precision ?\n",
    "#### 14. 4- How to define Recall, Sensitivity or True Positive Rate?\n",
    "#### 14. 5- How to define Specificity or True Negative Rate ?\n",
    "#### 14. 6- What is Receiver Operating Characteristic (ROC) and Area under-ROC curve (AUC-ROC)?\n",
    "#### 14. 7- What is Area Under the Precision-Recall Curve (AUC-PR)?\n",
    "#### 14. 8 - Classification Report Scikit-learn? \n",
    "#### 14. 9- How do we evaluate a classification report?\n",
    "- High recall + high precision ==> the class is perfectly handled by the model. \n",
    "- Low recall + high precision ==> the model can not detect the class well but is highly trustable when it does.\n",
    "- High recall + low precision ==> the class is well detected but model also includes points of other class in it. \n",
    "- Low recall + low precision ==> class is poorly handled by the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f838e",
   "metadata": {},
   "source": [
    "### 15- What are the performance metrics for Regression? \n",
    "\n",
    "- If error is high ==> we need either to change the model or retrain it with more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dad42",
   "metadata": {},
   "source": [
    "### 16. how to choose a classifier based on training dataset size?\n",
    "- If training set is small ==> it is better to use simple model with high bias and low variance seems to work better because they are less likely to overfit. \n",
    "- If training set is large ==> it is better to use model with low bias and high variance as this model type will tend to perform better with complex relationships. Example: Naive Bayes.\n",
    "-  Balancing variance and bias is essential for developing models that perform well on both training and unseen data.\n",
    "\n",
    "#### 16. 1-  What is data bias ?\n",
    "- It is when the available data used in the training phase is not representative of the real-world population or phenomen of study.\n",
    "- For example: when training data used to create a ml model has unfair discrepancies or inaccuracies. \n",
    "- The information provided by the data does not truly represent the situation.\n",
    "- The existence of biased data can lead to undesired and often unfair outcomes (discriminatory results) when the model is applied to testing data because the model will learn these biases too. \n",
    "- Various types of bias are existing : selection bias, measurement bias and confirmation bias.\n",
    "- Addressing data bias is an ongoing challenge in the field of machine learning, and researchers and practitioners are actively working to develop methods and tools to identify, measure, and mitigate bias in models.\n",
    "- To mitigate data bias in machine learning, it's crucial to accomplish well studied steps: collecting diverse and representative data, thoroughly processing it, and regularly checking model predictions to ensure fairness.\n",
    "- Example: a biased facial recognition model may perform poorly for certain demographic groups.\n",
    "\n",
    "#### 16. 2-  What is variance? \n",
    "\n",
    "- Understanding variance is crucial in assessing the stability and generalization capability of models.\n",
    "- It refers to the degree of spread or dispersion in a set of values.\n",
    "- It measures the variability of each individual data points (observation) from the mean (average) of the dataset:\n",
    "    - Higher variance: data points are more spread out from the mean ==> more dispersed distribution.\n",
    "    - Lower variance:  data points are closer to the mean ==> more concentrated distribution.\n",
    "- Formula:  $\\sigma^2 = { \\sum \\limits _{i=1} ^{n}(X_{i} - \\overline{X}) \\over {n-1}}$\n",
    "- The standard deviation ( $\\sigma$) is the square root of the variance.\n",
    "- If the predictions variance is :\n",
    "    - Low: predictions varying little from each other. \n",
    "    - High: overfitting + reading too deelpy into the noise+ good performance on training data +poor performance on testing data\n",
    "- Do not forget the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bac1a",
   "metadata": {},
   "source": [
    "### 16- What are the performance metrics for Clustering ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f019210e",
   "metadata": {},
   "source": [
    "### 17- What does hyperparameter tuning mean? \n",
    "\n",
    "#### 17. 1- What are the hyperparameter tuning techniques?\n",
    "\n",
    "#### 17. 2- Grid Search versus Random search? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c327507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f463e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2429fdbe",
   "metadata": {},
   "source": [
    "### 19 What is tranfert learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6824c6",
   "metadata": {},
   "source": [
    "### 20- What does interpolation and extrapolation means?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21936fcb",
   "metadata": {},
   "source": [
    "### 21- correlation matrix versus convariance matrix ? \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80e69d",
   "metadata": {},
   "source": [
    "### 21- Distributed computing versus parrallel computing ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc249517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ad53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144646f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cbcb741",
   "metadata": {},
   "source": [
    "### 10- What does Instance-Based Learning means : \n",
    "Also known as instance-based reasoning or memory-based learning, is a type of machine learning approach that makes predictions based on the similarity between new instances and instances in the training dataset. Instead of learning an explicit model during training, instance-based learning stores the entire training dataset and uses it to make predictions for new, unseen instances. K-Nearest Neighbors (KNN) is a classic example. \n",
    "\n",
    "It is suited for tasks where the relationships between input features and output labels are not easily captured by a simple model. It can be robust in the presence of noise and is capable of handling complex decision boundaries. However, it may be computationally expensive, especially when dealing with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec6543",
   "metadata": {},
   "source": [
    "### Why should we create a ML pipeline: \n",
    "A ML pipeline is an end to end construct that orchestrates the flow of data into and output from a ml model(set of multiple models). \n",
    "It is a way to modify and automate  the workflow it takes to produce a ml model \n",
    "multiple sequential steps from data extraction, preprocessing to model training and deplyment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f66d794",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87050441",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcb376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220d308f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d28d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
